Metadata-Version: 2.1
Name: fschat
Version: 0.2.8
Summary: An open platform for training, serving, and evaluating large language model based chatbots.
Project-URL: Homepage, https://github.com/lm-sys/fastchat
Project-URL: Bug Tracker, https://github.com/lm-sys/fastchat/issues
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: Apache Software License
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: accelerate
Requires-Dist: fastapi
Requires-Dist: gradio==3.23
Requires-Dist: httpx
Requires-Dist: markdown2[all]
Requires-Dist: nh3
Requires-Dist: numpy
Requires-Dist: prompt_toolkit>=3.0.0
Requires-Dist: pydantic
Requires-Dist: requests
Requires-Dist: rich>=10.0.0
Requires-Dist: sentencepiece
Requires-Dist: shortuuid
Requires-Dist: shortuuid
Requires-Dist: tokenizers>=0.12.1
Requires-Dist: torch
Requires-Dist: transformers<4.29.0,>=4.28.0
Requires-Dist: uvicorn
Requires-Dist: wandb
Provides-Extra: dev
Requires-Dist: black==23.3.0; extra == "dev"
Requires-Dist: pylint==2.8.2; extra == "dev"

## Training

This directory contains the training code for **UniversalNER**, which is adapted from the [FastChat](https://github.com/lm-sys/FastChat) library. 

###  **Changes Made:**
- ğŸ“ Added the conversation-style instruction tuning template.
- ğŸš€ Enhanced the training code to support lazy data processing.
- ğŸ› Fixed the bug leading to OOM (Out of Memory) during model saving.

### **License**
The training code is licensed under the **Apache 2.0** License.

### **Training**
1. Install the package:
```bash
pip3 install -e ".[model_worker,webui]"
```

2. Download UniversalNER data `train.json` from [Huggingface](https://huggingface.co/Universal-NER).

3. Run the training script:
```bash
sh train.sh
```

Note: Our model is trained with 8 A100 40G GPUs. If you encounter an OOM error during model saving, you can find solutions [here](https://github.com/pytorch/pytorch/issues/98823).
